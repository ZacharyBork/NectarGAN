{
    "config": {
        "DEVICE": "cuda:0",
        "DATAROOT": "E:/ML/test_data/pix2pix/test_set_01",
        "OUTPUT_DIRECTORY": "E:/ML/test_data/pix2pix/test_output_01",
        "EXPERIMENT_NAME": "test01",
        "DIRECTION": "BtoA",
        "NUM_EPOCHS": 1,
        "LEARNING_RATE": 2e-4,
        "BATCH_SIZE": 1,
        "NUM_WORKERS": 4,
        "INPUT_NC": 3,
        "LOAD_SIZE": 1024,
        "CROP_SIZE": 512,
        "LAMBDA_L1": 100.0,
        "DO_SOBEL_LOSS": false,
        "LAMBDA_SOBEL": 1.0,
        "DO_LAPLACIAN_LOSS": false,
        "LAMBDA_LAPLACIAN": 1.0,
        "BETA1": 0.5,
        "N_LAYERS_D": 3,
        "BASE_CHANNELS_D": 64,
        "MAX_CHANNELS_D": 512,
        "CONTINUE_TRAIN": false,
        "LOAD_EPOCH": 3,
        "SAVE_MODEL": true,
        "MODEL_SAVE_RATE": 1,
        "SAVE_EXAMPLES": false,
        "EXAMPLE_SAVE_RATE": 1,
        "NUM_EXAMPLES": 1,
        "UPDATE_FREQUENCY": 100
    },
    "notes": {
        "DEVICE": "Which device should torch cast to for training.",
        "DATAROOT": "Root directory of dataset, should contrain test/train/val folder structure.",
        "OUTPUT_DIRECTORY": "Root output directory where experiment output directory is created.",
        "EXPERIMENT_NAME": "Name of current experiment.",
        "DIRECTION": "Dataset direction [BtoA | AtoB].",
        "NUM_EPOCHS": "How many epochs to run the current train for.",
        "LEARNING_RATE": "Model learning rate. default: 2e-04",
        "BATCH_SIZE": "Training batch size. Pix2pix paper default is 1.",
        "NUM_WORKERS": "Number of subprocesses used to load data.",
        "INPUT_NC": "Number of channels in input image. 1 for mono, 3 for RGB",
        "LOAD_SIZE": "Size in pixels to load dataset images.",
        "CROP_SIZE": "Size in pixels to crop dataset images.",
        "LAMBDA_L1": "Scaling factor for generator L1 loss.",
        "DO_SOBEL_LOSS": "Enable generator Sobel loss.",
        "LAMBDA_SOBEL": "Scaling factor for generator Sobel loss.",
        "DO_LAPLACIAN_LOSS": "Enable generator Laplacian loss.",
        "LAMBDA_LAPLACIAN": "Scaling factor for generator Laplacian loss.",
        "BETA1": "Momentum term of Adam.",
        "N_LAYERS_D": "Number of discriminator layers.",
        "BASE_CHANNELS_D": "Filter count for first discriminator conv layer",
        "MAX_CHANNELS_D": "Max filters per discriminator conv layer.",
        "CONTINUE_TRAIN": "Resume training of model from a checkpoint.",
        "LOAD_EPOCH": "Epoch to load if CONTINUE_TRAIN is true.",
        "SAVE_MODEL": "Save checkpoint files.",
        "MODEL_SAVE_RATE": "Rate in epochs at which to save checkpoint files if SAVE_MODEL is true.",
        "SAVE_EXAMPLES": "Load and eval the model and save example images.",
        "EXAMPLE_SAVE_RATE": "Rate in epochs at which to save example images if SAVE_EXAMPLES is true.",
        "NUM_EXAMPLES": "Number of examples to save each time when SAVE_EXAMPLES is true",
        "UPDATE_FREQUENCY": "Frequency (in iterations) of updates to loss and visualizer data."
    }
}